{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume Demand Forecast for Multiple Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Project purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A company has a large portfolio of products distributed to retailers through agencies. There are thousands of unique agency-SKU/product combinations. In order to plan its production and distribution as well as help agencies with their planning, it is important for the company to have an accurate estimate of demand at SKU level for each agency.\n",
    "\n",
    "Our purpose is to achieve the following using DeepAR algorithm:\n",
    "- taking advantage of DeepAR's RNN framework. To predict product demand that's not only trained on their own historical data, but also trained on historical data of other variables(e.g., sales price and promotion price) that have impact on product demand.  \n",
    "- predicting the monthly demand volume(hectoliters) for each Agency-SKU combination (350 Agency-SKU combinations in total) for year 2018 based on data from 2013-2017.\n",
    "- handling cold start problems, which is to do volume demand forecast for new Agency-SKU combinations that we don't have any data on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up Sagemaker instance and load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Sagemaker instance and S3 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "from random import shuffle\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "# import boto3\n",
    "# import s3fs\n",
    "# import sagemaker\n",
    "# from sagemaker import get_execution_role\n",
    "# from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(4216)\n",
    "random.seed(4216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the execution role for the notebook instance. This is the IAM role created for the notebook instance that creates an access b/w S3 bucket and this instance\n",
    "#load our data saved in S3 bucket\n",
    "df_historical_volume = pd.read_csv(\"historical_volume.csv\")\n",
    "df_price_sales_promotion = pd.read_csv(\"price_sales_promotion.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Loading data\n",
    "We have two datasets available for analysis. \n",
    "- historical_volume.csv : holds volume(hectoliters) sales data at Agency-SKU-month level from Jan 2013 to Dec 2017\n",
    "- price_sales_promotion.csv : Holds price (dollar/hectoliters), sales(dollar/hectoliters) and promotion(dollar/hectoliter) at Agency-SKU-month level from Jan 2013 to Dec 2017. The relationship between these 3 variables: price = sales + promotion\n",
    "\n",
    "Data source: https://www.kaggle.com/utathya/future-volume-prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>SKU</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12147</th>\n",
       "      <td>Agency_28</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>201704</td>\n",
       "      <td>36.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11652</th>\n",
       "      <td>Agency_26</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>201604</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Agency_50</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>201301</td>\n",
       "      <td>1144.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Agency     SKU  YearMonth    Volume\n",
       "12147  Agency_28  SKU_01     201704    36.828\n",
       "11652  Agency_26  SKU_03     201604     0.000\n",
       "67     Agency_50  SKU_01     201301  1144.800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historical_volume.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>SKU</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Promotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>Agency_46</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>201302</td>\n",
       "      <td>1271.634938</td>\n",
       "      <td>1252.793957</td>\n",
       "      <td>18.840981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>Agency_21</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>201404</td>\n",
       "      <td>1332.054913</td>\n",
       "      <td>1100.508520</td>\n",
       "      <td>231.546393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18203</th>\n",
       "      <td>Agency_54</td>\n",
       "      <td>SKU_14</td>\n",
       "      <td>201305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>Agency_32</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>201710</td>\n",
       "      <td>1919.156779</td>\n",
       "      <td>1610.401856</td>\n",
       "      <td>308.754923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11447</th>\n",
       "      <td>Agency_32</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>201608</td>\n",
       "      <td>2170.270691</td>\n",
       "      <td>1788.125455</td>\n",
       "      <td>382.145236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Agency     SKU  YearMonth        Price        Sales  Promotions\n",
       "8760   Agency_46  SKU_03     201302  1271.634938  1252.793957   18.840981\n",
       "7330   Agency_21  SKU_03     201404  1332.054913  1100.508520  231.546393\n",
       "18203  Agency_54  SKU_14     201305     0.000000     0.000000    0.000000\n",
       "14937  Agency_32  SKU_05     201710  1919.156779  1610.401856  308.754923\n",
       "11447  Agency_32  SKU_04     201608  2170.270691  1788.125455  382.145236"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price_sales_promotion.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data cleaning\n",
    "To manipulate data to the correct format required by SageMaker DeepAR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Combining two datasets\n",
    "Combine two datasets by 'Agency', 'SKU', 'YearMonth'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>SKU</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Promotions</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20970</th>\n",
       "      <td>Agency_60</td>\n",
       "      <td>SKU_23</td>\n",
       "      <td>201507</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20166</th>\n",
       "      <td>Agency_59</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>201307</td>\n",
       "      <td>8823.8175</td>\n",
       "      <td>1289.293543</td>\n",
       "      <td>1207.097405</td>\n",
       "      <td>82.196138</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13975</th>\n",
       "      <td>Agency_43</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>201708</td>\n",
       "      <td>433.9440</td>\n",
       "      <td>1686.687500</td>\n",
       "      <td>1369.531654</td>\n",
       "      <td>317.155846</td>\n",
       "      <td>2017-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>Agency_57</td>\n",
       "      <td>SKU_07</td>\n",
       "      <td>201711</td>\n",
       "      <td>134.5200</td>\n",
       "      <td>1593.812940</td>\n",
       "      <td>1356.976004</td>\n",
       "      <td>236.836936</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13828</th>\n",
       "      <td>Agency_42</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>201505</td>\n",
       "      <td>129.2697</td>\n",
       "      <td>2089.730546</td>\n",
       "      <td>1953.573065</td>\n",
       "      <td>136.157481</td>\n",
       "      <td>2015-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Agency     SKU  YearMonth     Volume        Price        Sales  \\\n",
       "20970  Agency_60  SKU_23     201507     0.0000     0.000000     0.000000   \n",
       "20166  Agency_59  SKU_01     201307  8823.8175  1289.293543  1207.097405   \n",
       "13975  Agency_43  SKU_01     201708   433.9440  1686.687500  1369.531654   \n",
       "19558  Agency_57  SKU_07     201711   134.5200  1593.812940  1356.976004   \n",
       "13828  Agency_42  SKU_04     201505   129.2697  2089.730546  1953.573065   \n",
       "\n",
       "       Promotions       time  \n",
       "20970    0.000000 2015-07-01  \n",
       "20166   82.196138 2013-07-01  \n",
       "13975  317.155846 2017-08-01  \n",
       "19558  236.836936 2017-11-01  \n",
       "13828  136.157481 2015-05-01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_historical_volume.sort_values(by = ['Agency', 'SKU', 'YearMonth'], inplace = False, ignore_index = True)\n",
    "df2 = df_price_sales_promotion.sort_values(by = ['Agency', 'SKU', 'YearMonth'], inplace = False, ignore_index = True)\n",
    "\n",
    "df = pd.merge(df1, df2, how = 'inner', on = ['Agency', 'SKU', 'YearMonth'])\n",
    "\n",
    "df['time'] = pd.to_datetime(df['YearMonth'], format = '%Y%m')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Label encoding \n",
    "Use label encoders for 2 category variables-- Agency and SKU since DeepAR only accepts categories represented by number. There are 58 different agencies and 25 different SKUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/anaconda3/envs/playground/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mahsa/anaconda3/envs/playground/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/mahsa/anaconda3/envs/playground/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mahsa/anaconda3/envs/playground/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>SKU</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Promotions</th>\n",
       "      <th>time</th>\n",
       "      <th>Agency_le</th>\n",
       "      <th>SKU_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16140</th>\n",
       "      <td>Agency_49</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>201301</td>\n",
       "      <td>2225.4480</td>\n",
       "      <td>1226.108241</td>\n",
       "      <td>1220.071220</td>\n",
       "      <td>6.037021</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7238</th>\n",
       "      <td>Agency_21</td>\n",
       "      <td>SKU_21</td>\n",
       "      <td>201603</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Agency_01</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>201406</td>\n",
       "      <td>69.5412</td>\n",
       "      <td>1393.911321</td>\n",
       "      <td>1284.701623</td>\n",
       "      <td>109.209698</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>Agency_12</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>201606</td>\n",
       "      <td>2992.5645</td>\n",
       "      <td>1520.897131</td>\n",
       "      <td>1239.782100</td>\n",
       "      <td>281.115031</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>Agency_23</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>201505</td>\n",
       "      <td>828.5910</td>\n",
       "      <td>1486.594316</td>\n",
       "      <td>1272.961305</td>\n",
       "      <td>213.633011</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Agency     SKU  YearMonth     Volume        Price        Sales  \\\n",
       "16140  Agency_49  SKU_01     201301  2225.4480  1226.108241  1220.071220   \n",
       "7238   Agency_21  SKU_21     201603     0.0000     0.000000     0.000000   \n",
       "137    Agency_01  SKU_03     201406    69.5412  1393.911321  1284.701623   \n",
       "4241   Agency_12  SKU_05     201606  2992.5645  1520.897131  1239.782100   \n",
       "7828   Agency_23  SKU_05     201505   828.5910  1486.594316  1272.961305   \n",
       "\n",
       "       Promotions       time  Agency_le  SKU_le  \n",
       "16140    6.037021 2013-01-01         46       0  \n",
       "7238     0.000000 2016-03-01         18      15  \n",
       "137    109.209698 2014-06-01          0       2  \n",
       "4241   281.115031 2016-06-01         10       4  \n",
       "7828   213.633011 2015-05-01         20       4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#use label encoding to encode 'Agency' and 'SKU' to numbers \n",
    "agency_le = preprocessing.LabelEncoder()\n",
    "df['Agency_le'] = agency_le.fit_transform(df['Agency'])\n",
    "sku_le = preprocessing.LabelEncoder()\n",
    "df['SKU_le'] = sku_le.fit_transform(df['SKU'])\n",
    "\n",
    "# df.tail(10)\n",
    "\n",
    "# agency_label = agency_le.transform(agency_le.classes_)\n",
    "# agency_name = agency_le.classes_\n",
    "# agency_label_encoder = pd.DataFrame(zip(agency_name, agency_label), columns = ['agency_name', 'agency_label']).to_string(index = False)\n",
    "\n",
    "\n",
    "# sku_label = sku_le.transform(sku_le.classes_)\n",
    "# sku_name = sku_le.classes_\n",
    "# sku_label_encoder = pd.DataFrame(zip(sku_name, sku_label), columns = ['sku_name', 'sku_label']).to_string(index = False)\n",
    "\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Transforming the data format\n",
    "We start to transform data from a vertical format to a dictionary format using group_by and merge etc. After grouping the data by 'Agency' and 'SKU', we can see we have 350 time series that we will need to predict simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency_le</th>\n",
       "      <th>SKU_le</th>\n",
       "      <th>volume</th>\n",
       "      <th>sales</th>\n",
       "      <th>promotions</th>\n",
       "      <th>cat_agency_sku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[80.676, 98.064, 133.704, 147.312, 175.608, 18...</td>\n",
       "      <td>[1033.432731, 1065.417195, 1101.133633, 1138.2...</td>\n",
       "      <td>[108.067269, 76.082805, 78.212187, 88.404143, ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[78.408, 99.252, 137.268, 135.864, 167.832, 15...</td>\n",
       "      <td>[969.1862085, 996.9507621, 1061.272227, 1113.6...</td>\n",
       "      <td>[104.9715905, 77.9940829, 67.717594, 87.975954...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[35.955, 45.684, 53.298, 61.8426, 65.142, 94.8...</td>\n",
       "      <td>[1141.894806, 1154.786791, 1183.434397, 1197.8...</td>\n",
       "      <td>[97.839237, 84.947252, 82.374114, 107.075669, ...</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[230.2956, 270.4887, 411.4521, 396.5634, 498.0...</td>\n",
       "      <td>[1467.68186, 1500.037283, 1603.69942, 1589.691...</td>\n",
       "      <td>[258.029967, 228.508225, 166.576616, 225.17043...</td>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[15.975, 16.4223, 30.672, 26.5185, 27.4131, 26...</td>\n",
       "      <td>[1172.763381, 1171.803584, 1243.893486, 1242.9...</td>\n",
       "      <td>[87.559436, 86.793582, 64.920555, 110.418633, ...</td>\n",
       "      <td>[0, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>[335.016, 446.9418, 968.247, 580.1868, 689.151...</td>\n",
       "      <td>[1174.171358, 1178.179712, 1213.793473, 1159.6...</td>\n",
       "      <td>[91.544013, 87.646841, 81.781457, 154.011194, ...</td>\n",
       "      <td>[57, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>[2201.0355, 2269.728, 2594.0205, 2622.648, 280...</td>\n",
       "      <td>[1637.073176, 1631.781117, 1669.963723, 1741.0...</td>\n",
       "      <td>[134.263949, 136.967854, 137.911583, 137.24238...</td>\n",
       "      <td>[57, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>[2005.3098, 2111.895, 2270.30325, 2408.5185, 2...</td>\n",
       "      <td>[1233.085829, 1228.666919, 1258.891157, 1315.2...</td>\n",
       "      <td>[76.002875, 80.120268, 82.490385, 85.707017, 8...</td>\n",
       "      <td>[57, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>[35.8425, 56.1975, 70.8, 69.4725, 79.2075, 69....</td>\n",
       "      <td>[1058.74021, 1048.839219, 1095.033887, 1132.93...</td>\n",
       "      <td>[68.537488, 76.783454, 73.649427, 92.264551, 9...</td>\n",
       "      <td>[57, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[57, 17]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Agency_le  SKU_le                                             volume  \\\n",
       "0            0       0  [80.676, 98.064, 133.704, 147.312, 175.608, 18...   \n",
       "1            0       1  [78.408, 99.252, 137.268, 135.864, 167.832, 15...   \n",
       "2            0       2  [35.955, 45.684, 53.298, 61.8426, 65.142, 94.8...   \n",
       "3            0       3  [230.2956, 270.4887, 411.4521, 396.5634, 498.0...   \n",
       "4            0       4  [15.975, 16.4223, 30.672, 26.5185, 27.4131, 26...   \n",
       "..         ...     ...                                                ...   \n",
       "345         57       2  [335.016, 446.9418, 968.247, 580.1868, 689.151...   \n",
       "346         57       3  [2201.0355, 2269.728, 2594.0205, 2622.648, 280...   \n",
       "347         57       4  [2005.3098, 2111.895, 2270.30325, 2408.5185, 2...   \n",
       "348         57       6  [35.8425, 56.1975, 70.8, 69.4725, 79.2075, 69....   \n",
       "349         57      17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 sales  \\\n",
       "0    [1033.432731, 1065.417195, 1101.133633, 1138.2...   \n",
       "1    [969.1862085, 996.9507621, 1061.272227, 1113.6...   \n",
       "2    [1141.894806, 1154.786791, 1183.434397, 1197.8...   \n",
       "3    [1467.68186, 1500.037283, 1603.69942, 1589.691...   \n",
       "4    [1172.763381, 1171.803584, 1243.893486, 1242.9...   \n",
       "..                                                 ...   \n",
       "345  [1174.171358, 1178.179712, 1213.793473, 1159.6...   \n",
       "346  [1637.073176, 1631.781117, 1669.963723, 1741.0...   \n",
       "347  [1233.085829, 1228.666919, 1258.891157, 1315.2...   \n",
       "348  [1058.74021, 1048.839219, 1095.033887, 1132.93...   \n",
       "349  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            promotions cat_agency_sku  \n",
       "0    [108.067269, 76.082805, 78.212187, 88.404143, ...         [0, 0]  \n",
       "1    [104.9715905, 77.9940829, 67.717594, 87.975954...         [0, 1]  \n",
       "2    [97.839237, 84.947252, 82.374114, 107.075669, ...         [0, 2]  \n",
       "3    [258.029967, 228.508225, 166.576616, 225.17043...         [0, 3]  \n",
       "4    [87.559436, 86.793582, 64.920555, 110.418633, ...         [0, 4]  \n",
       "..                                                 ...            ...  \n",
       "345  [91.544013, 87.646841, 81.781457, 154.011194, ...        [57, 2]  \n",
       "346  [134.263949, 136.967854, 137.911583, 137.24238...        [57, 3]  \n",
       "347  [76.002875, 80.120268, 82.490385, 85.707017, 8...        [57, 4]  \n",
       "348  [68.537488, 76.783454, 73.649427, 92.264551, 9...        [57, 6]  \n",
       "349  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       [57, 17]  \n",
       "\n",
       "[350 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by = df.groupby(['Agency_le', 'SKU_le']) #  350 agency-SKU combination time series in total\n",
    "volume_series = group_by['Volume'].apply(list).reset_index(name = 'volume')\n",
    "sales_series = group_by['Sales'].apply(list).reset_index(name = 'sales')\n",
    "promotion_series = group_by['Promotions'].apply(list).reset_index(name = 'promotions')\n",
    "\n",
    "df_merge = pd.merge(volume_series, sales_series, how= 'inner', on= ['Agency_le','SKU_le']) \n",
    "df_merge2 = pd.merge(df_merge, promotion_series, how = 'inner', on = ['Agency_le','SKU_le'])\n",
    "df_merge2['cat_agency_sku'] = df_merge2[['Agency_le', 'SKU_le']].apply(lambda x: list(x), axis=1)\n",
    "\n",
    "#check the lengths of each dynamic features.len should be 60.\n",
    "\n",
    "np.where(df_merge2.volume.apply(lambda x: len(x)) != 60)\n",
    "np.where(df_merge2.sales.apply(lambda x: len(x)) !=60)\n",
    "np.where(df_merge2.promotions.apply(lambda x: len(x)) !=60)\n",
    "\n",
    "df_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>SKU</th>\n",
       "      <th>average_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Agency_55</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>566.857943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Agency_47</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>0.212940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Agency_31</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>944.800548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Agency     SKU  average_volume\n",
       "314  Agency_55  SKU_05      566.857943\n",
       "258  Agency_47  SKU_05        0.212940\n",
       "182  Agency_31  SKU_04      944.800548"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# monthly volume, sales and promotions for each agency and sku averaged over 2013-2017\n",
    "Agency_SKU = df.groupby(['Agency','SKU'])\n",
    "Agency_SKU_mean = Agency_SKU['Volume'].mean().reset_index(name = 'average_volume')\n",
    "Agency_SKU_mean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Spliting data to training and test sets\n",
    "- training set: 48-month data from 2013-01 to 2016-12\n",
    "- test set: 12-month data from 2017-01 to 2017-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2['sales_promotions'] = df_merge2.apply(lambda x: np.vstack([np.array(x['sales']),np.array(x['promotions'])]),axis = 1)\n",
    "df_merge2['training_volume'] = df_merge2['volume'].apply(lambda x: x[:48])\n",
    "df_merge2['training_sales'] = df_merge2['sales'].apply(lambda x: x[:48])\n",
    "df_merge2['training_promotions'] = df_merge2['promotions'].apply(lambda x: x[:48])\n",
    "df_merge2['training_sales_promotions'] = df_merge2.apply(lambda x: np.vstack([np.array(x['training_sales']),np.array(x['training_promotions'])]),axis = 1)\n",
    "\n",
    "df_merge2['test_volume'] = df_merge2['volume'].apply(lambda x: x[48:])\n",
    "df_merge2['test_sales'] = df_merge2['sales'].apply(lambda x: x[48:])\n",
    "df_merge2['test_promotions'] = df_merge2['promotions'].apply(lambda x: x[48:])\n",
    "df_merge2['test_sales_promotions'] = df_merge2.apply(lambda x: np.vstack([np.array(x['test_sales']),np.array(x['test_promotions'])]),axis = 1)\n",
    "\n",
    "# create the dynamic_feat: sales and promotions for batch transform data. \n",
    "df_merge2['batch_sales'] = df_merge2.apply(lambda x: x.sales + x.test_sales, axis = 1)\n",
    "df_merge2['batch_promotions'] = df_merge2.apply(lambda x: x.promotions + x.test_promotions, axis = 1)\n",
    "df_merge2['batch_sales_promotions'] = df_merge2.apply(lambda x: np.vstack([np.array(x['batch_sales']),np.array(x['batch_promotions'])]),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency_le</th>\n",
       "      <th>SKU_le</th>\n",
       "      <th>volume</th>\n",
       "      <th>sales</th>\n",
       "      <th>promotions</th>\n",
       "      <th>cat_agency_sku</th>\n",
       "      <th>sales_promotions</th>\n",
       "      <th>training_volume</th>\n",
       "      <th>training_sales</th>\n",
       "      <th>training_promotions</th>\n",
       "      <th>training_sales_promotions</th>\n",
       "      <th>test_volume</th>\n",
       "      <th>test_sales</th>\n",
       "      <th>test_promotions</th>\n",
       "      <th>test_sales_promotions</th>\n",
       "      <th>batch_sales</th>\n",
       "      <th>batch_promotions</th>\n",
       "      <th>batch_sales_promotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>[61.2162, 68.6925, 77.1273, 86.8401, 78.7887, ...</td>\n",
       "      <td>[1315.562498, 1313.954307, 1345.432367, 1382.8...</td>\n",
       "      <td>[0.408201, 0.242516, 0.0, 0.0, 0.0, 0.0, 6.625...</td>\n",
       "      <td>[51, 4]</td>\n",
       "      <td>[[1315.562498, 1313.954307, 1345.432367, 1382....</td>\n",
       "      <td>[61.2162, 68.6925, 77.1273, 86.8401, 78.7887, ...</td>\n",
       "      <td>[1315.562498, 1313.954307, 1345.432367, 1382.8...</td>\n",
       "      <td>[0.408201, 0.242516, 0.0, 0.0, 0.0, 0.0, 6.625...</td>\n",
       "      <td>[[1315.562498, 1313.954307, 1345.432367, 1382....</td>\n",
       "      <td>[88.54875, 97.98375, 105.76845, 129.3336, 101....</td>\n",
       "      <td>[1590.982366, 1498.013334, 1495.149208, 1392.5...</td>\n",
       "      <td>[208.760208, 327.418684, 329.540315, 432.25821...</td>\n",
       "      <td>[[1590.982366, 1498.013334, 1495.149208, 1392....</td>\n",
       "      <td>[1315.562498, 1313.954307, 1345.432367, 1382.8...</td>\n",
       "      <td>[0.408201, 0.242516, 0.0, 0.0, 0.0, 0.0, 6.625...</td>\n",
       "      <td>[[1315.562498, 1313.954307, 1345.432367, 1382....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 2062.908, 2285.388, 2646.864, 2697.3, 25...</td>\n",
       "      <td>[0.0, 1128.240729, 1144.175252, 1186.580542, 1...</td>\n",
       "      <td>[0.0, 76.790193, 81.790689, 81.515584, 84.8765...</td>\n",
       "      <td>[11, 1]</td>\n",
       "      <td>[[0.0, 1128.240729, 1144.175252, 1186.580542, ...</td>\n",
       "      <td>[0.0, 2062.908, 2285.388, 2646.864, 2697.3, 25...</td>\n",
       "      <td>[0.0, 1128.240729, 1144.175252, 1186.580542, 1...</td>\n",
       "      <td>[0.0, 76.790193, 81.790689, 81.515584, 84.8765...</td>\n",
       "      <td>[[0.0, 1128.240729, 1144.175252, 1186.580542, ...</td>\n",
       "      <td>[4246.344, 5583.06, 5704.56, 6451.272, 6054.69...</td>\n",
       "      <td>[1320.621094, 1317.834057, 1316.536229, 1225.7...</td>\n",
       "      <td>[307.382968, 319.813473, 320.594756, 412.30206...</td>\n",
       "      <td>[[1320.621094, 1317.834057, 1316.536229, 1225....</td>\n",
       "      <td>[0.0, 1128.240729, 1144.175252, 1186.580542, 1...</td>\n",
       "      <td>[0.0, 76.790193, 81.790689, 81.515584, 84.8765...</td>\n",
       "      <td>[[0.0, 1128.240729, 1144.175252, 1186.580542, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>[17.172, 23.976, 26.784, 27.0, 22.032, 10.584,...</td>\n",
       "      <td>[1066.777516, 1069.345439, 1096.779738, 1126.7...</td>\n",
       "      <td>[102.474842, 99.267737, 104.064264, 108.41275,...</td>\n",
       "      <td>[22, 0]</td>\n",
       "      <td>[[1066.777516, 1069.345439, 1096.779738, 1126....</td>\n",
       "      <td>[17.172, 23.976, 26.784, 27.0, 22.032, 10.584,...</td>\n",
       "      <td>[1066.777516, 1069.345439, 1096.779738, 1126.7...</td>\n",
       "      <td>[102.474842, 99.267737, 104.064264, 108.41275,...</td>\n",
       "      <td>[[1066.777516, 1069.345439, 1096.779738, 1126....</td>\n",
       "      <td>[8.532, 5.076, 5.724, 13.176, 4.104, 2.268, 3....</td>\n",
       "      <td>[1464.827531, 1303.945479, 1228.253538, 1202.5...</td>\n",
       "      <td>[311.206488, 340.117021, 415.808962, 441.54149...</td>\n",
       "      <td>[[1464.827531, 1303.945479, 1228.253538, 1202....</td>\n",
       "      <td>[1066.777516, 1069.345439, 1096.779738, 1126.7...</td>\n",
       "      <td>[102.474842, 99.267737, 104.064264, 108.41275,...</td>\n",
       "      <td>[[1066.777516, 1069.345439, 1096.779738, 1126....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>[64.908, 77.004, 92.664, 106.056, 113.184, 107...</td>\n",
       "      <td>[912.4412166, 902.3444037, 915.351192, 936.528...</td>\n",
       "      <td>[80.407845, 82.8398817, 72.6215364, 92.1922121...</td>\n",
       "      <td>[24, 5]</td>\n",
       "      <td>[[912.4412166, 902.3444037, 915.351192, 936.52...</td>\n",
       "      <td>[64.908, 77.004, 92.664, 106.056, 113.184, 107...</td>\n",
       "      <td>[912.4412166, 902.3444037, 915.351192, 936.528...</td>\n",
       "      <td>[80.407845, 82.8398817, 72.6215364, 92.1922121...</td>\n",
       "      <td>[[912.4412166, 902.3444037, 915.351192, 936.52...</td>\n",
       "      <td>[7.992, 8.424, 8.964, 10.692, 14.256, 10.152, ...</td>\n",
       "      <td>[1319.831081, 1313.798077, 1299.143073, 1298.0...</td>\n",
       "      <td>[88.226351, 108.536058, 73.545933, 69.006314, ...</td>\n",
       "      <td>[[1319.831081, 1313.798077, 1299.143073, 1298....</td>\n",
       "      <td>[912.4412166, 902.3444037, 915.351192, 936.528...</td>\n",
       "      <td>[80.407845, 82.8398817, 72.6215364, 92.1922121...</td>\n",
       "      <td>[[912.4412166, 902.3444037, 915.351192, 936.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[510.6456, 498.4632, 538.479, 624.2634, 680.69...</td>\n",
       "      <td>[1157.050899, 1156.605128, 1174.192448, 1184.4...</td>\n",
       "      <td>[93.560341, 94.08717, 99.040934, 120.870774, 2...</td>\n",
       "      <td>[10, 2]</td>\n",
       "      <td>[[1157.050899, 1156.605128, 1174.192448, 1184....</td>\n",
       "      <td>[510.6456, 498.4632, 538.479, 624.2634, 680.69...</td>\n",
       "      <td>[1157.050899, 1156.605128, 1174.192448, 1184.4...</td>\n",
       "      <td>[93.560341, 94.08717, 99.040934, 120.870774, 2...</td>\n",
       "      <td>[[1157.050899, 1156.605128, 1174.192448, 1184....</td>\n",
       "      <td>[587.487, 455.19225, 403.9971, 560.9826, 506.5...</td>\n",
       "      <td>[1312.888415, 1396.164439, 1378.896139, 1319.6...</td>\n",
       "      <td>[343.295419, 319.360898, 341.446189, 406.41730...</td>\n",
       "      <td>[[1312.888415, 1396.164439, 1378.896139, 1319....</td>\n",
       "      <td>[1157.050899, 1156.605128, 1174.192448, 1184.4...</td>\n",
       "      <td>[93.560341, 94.08717, 99.040934, 120.870774, 2...</td>\n",
       "      <td>[[1157.050899, 1156.605128, 1174.192448, 1184....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Agency_le  SKU_le                                             volume  \\\n",
       "307         51       4  [61.2162, 68.6925, 77.1273, 86.8401, 78.7887, ...   \n",
       "73          11       1  [0.0, 2062.908, 2285.388, 2646.864, 2697.3, 25...   \n",
       "138         22       0  [17.172, 23.976, 26.784, 27.0, 22.032, 10.584,...   \n",
       "156         24       5  [64.908, 77.004, 92.664, 106.056, 113.184, 107...   \n",
       "68          10       2  [510.6456, 498.4632, 538.479, 624.2634, 680.69...   \n",
       "\n",
       "                                                 sales  \\\n",
       "307  [1315.562498, 1313.954307, 1345.432367, 1382.8...   \n",
       "73   [0.0, 1128.240729, 1144.175252, 1186.580542, 1...   \n",
       "138  [1066.777516, 1069.345439, 1096.779738, 1126.7...   \n",
       "156  [912.4412166, 902.3444037, 915.351192, 936.528...   \n",
       "68   [1157.050899, 1156.605128, 1174.192448, 1184.4...   \n",
       "\n",
       "                                            promotions cat_agency_sku  \\\n",
       "307  [0.408201, 0.242516, 0.0, 0.0, 0.0, 0.0, 6.625...        [51, 4]   \n",
       "73   [0.0, 76.790193, 81.790689, 81.515584, 84.8765...        [11, 1]   \n",
       "138  [102.474842, 99.267737, 104.064264, 108.41275,...        [22, 0]   \n",
       "156  [80.407845, 82.8398817, 72.6215364, 92.1922121...        [24, 5]   \n",
       "68   [93.560341, 94.08717, 99.040934, 120.870774, 2...        [10, 2]   \n",
       "\n",
       "                                      sales_promotions  \\\n",
       "307  [[1315.562498, 1313.954307, 1345.432367, 1382....   \n",
       "73   [[0.0, 1128.240729, 1144.175252, 1186.580542, ...   \n",
       "138  [[1066.777516, 1069.345439, 1096.779738, 1126....   \n",
       "156  [[912.4412166, 902.3444037, 915.351192, 936.52...   \n",
       "68   [[1157.050899, 1156.605128, 1174.192448, 1184....   \n",
       "\n",
       "                                       training_volume  \\\n",
       "307  [61.2162, 68.6925, 77.1273, 86.8401, 78.7887, ...   \n",
       "73   [0.0, 2062.908, 2285.388, 2646.864, 2697.3, 25...   \n",
       "138  [17.172, 23.976, 26.784, 27.0, 22.032, 10.584,...   \n",
       "156  [64.908, 77.004, 92.664, 106.056, 113.184, 107...   \n",
       "68   [510.6456, 498.4632, 538.479, 624.2634, 680.69...   \n",
       "\n",
       "                                        training_sales  \\\n",
       "307  [1315.562498, 1313.954307, 1345.432367, 1382.8...   \n",
       "73   [0.0, 1128.240729, 1144.175252, 1186.580542, 1...   \n",
       "138  [1066.777516, 1069.345439, 1096.779738, 1126.7...   \n",
       "156  [912.4412166, 902.3444037, 915.351192, 936.528...   \n",
       "68   [1157.050899, 1156.605128, 1174.192448, 1184.4...   \n",
       "\n",
       "                                   training_promotions  \\\n",
       "307  [0.408201, 0.242516, 0.0, 0.0, 0.0, 0.0, 6.625...   \n",
       "73   [0.0, 76.790193, 81.790689, 81.515584, 84.8765...   \n",
       "138  [102.474842, 99.267737, 104.064264, 108.41275,...   \n",
       "156  [80.407845, 82.8398817, 72.6215364, 92.1922121...   \n",
       "68   [93.560341, 94.08717, 99.040934, 120.870774, 2...   \n",
       "\n",
       "                             training_sales_promotions  \\\n",
       "307  [[1315.562498, 1313.954307, 1345.432367, 1382....   \n",
       "73   [[0.0, 1128.240729, 1144.175252, 1186.580542, ...   \n",
       "138  [[1066.777516, 1069.345439, 1096.779738, 1126....   \n",
       "156  [[912.4412166, 902.3444037, 915.351192, 936.52...   \n",
       "68   [[1157.050899, 1156.605128, 1174.192448, 1184....   \n",
       "\n",
       "                                           test_volume  \\\n",
       "307  [88.54875, 97.98375, 105.76845, 129.3336, 101....   \n",
       "73   [4246.344, 5583.06, 5704.56, 6451.272, 6054.69...   \n",
       "138  [8.532, 5.076, 5.724, 13.176, 4.104, 2.268, 3....   \n",
       "156  [7.992, 8.424, 8.964, 10.692, 14.256, 10.152, ...   \n",
       "68   [587.487, 455.19225, 403.9971, 560.9826, 506.5...   \n",
       "\n",
       "                                            test_sales  \\\n",
       "307  [1590.982366, 1498.013334, 1495.149208, 1392.5...   \n",
       "73   [1320.621094, 1317.834057, 1316.536229, 1225.7...   \n",
       "138  [1464.827531, 1303.945479, 1228.253538, 1202.5...   \n",
       "156  [1319.831081, 1313.798077, 1299.143073, 1298.0...   \n",
       "68   [1312.888415, 1396.164439, 1378.896139, 1319.6...   \n",
       "\n",
       "                                       test_promotions  \\\n",
       "307  [208.760208, 327.418684, 329.540315, 432.25821...   \n",
       "73   [307.382968, 319.813473, 320.594756, 412.30206...   \n",
       "138  [311.206488, 340.117021, 415.808962, 441.54149...   \n",
       "156  [88.226351, 108.536058, 73.545933, 69.006314, ...   \n",
       "68   [343.295419, 319.360898, 341.446189, 406.41730...   \n",
       "\n",
       "                                 test_sales_promotions  \\\n",
       "307  [[1590.982366, 1498.013334, 1495.149208, 1392....   \n",
       "73   [[1320.621094, 1317.834057, 1316.536229, 1225....   \n",
       "138  [[1464.827531, 1303.945479, 1228.253538, 1202....   \n",
       "156  [[1319.831081, 1313.798077, 1299.143073, 1298....   \n",
       "68   [[1312.888415, 1396.164439, 1378.896139, 1319....   \n",
       "\n",
       "                                           batch_sales  \\\n",
       "307  [1315.562498, 1313.954307, 1345.432367, 1382.8...   \n",
       "73   [0.0, 1128.240729, 1144.175252, 1186.580542, 1...   \n",
       "138  [1066.777516, 1069.345439, 1096.779738, 1126.7...   \n",
       "156  [912.4412166, 902.3444037, 915.351192, 936.528...   \n",
       "68   [1157.050899, 1156.605128, 1174.192448, 1184.4...   \n",
       "\n",
       "                                      batch_promotions  \\\n",
       "307  [0.408201, 0.242516, 0.0, 0.0, 0.0, 0.0, 6.625...   \n",
       "73   [0.0, 76.790193, 81.790689, 81.515584, 84.8765...   \n",
       "138  [102.474842, 99.267737, 104.064264, 108.41275,...   \n",
       "156  [80.407845, 82.8398817, 72.6215364, 92.1922121...   \n",
       "68   [93.560341, 94.08717, 99.040934, 120.870774, 2...   \n",
       "\n",
       "                                batch_sales_promotions  \n",
       "307  [[1315.562498, 1313.954307, 1345.432367, 1382....  \n",
       "73   [[0.0, 1128.240729, 1144.175252, 1186.580542, ...  \n",
       "138  [[1066.777516, 1069.345439, 1096.779738, 1126....  \n",
       "156  [[912.4412166, 902.3444037, 915.351192, 936.52...  \n",
       "68   [[1157.050899, 1156.605128, 1174.192448, 1184....  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_clean = pd.concat([df_merge2,Agency_SKU_mean], axis = 1)\n",
    "full_df_clean.sample(3)\n",
    "\n",
    "df_merge2[\"sales_promotions\"][0]\n",
    "\n",
    "df_merge2.sample(5)\n",
    "\n",
    "len(df_merge2[\"volume\"][0])\n",
    "\n",
    "print(len(df_merge2[\"sales_promotions\"][0][0]))\n",
    "\n",
    "\n",
    "df_merge2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Transforming training and test sets to dictionary format\n",
    "Transforming data to dictionary format to be prepared for json line format required by DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_training = pd.Timestamp(\"2013-01-01 00:00:00\")\n",
    "\n",
    "\n",
    "training_data = []\n",
    "for _,row in df_merge2.iterrows():\n",
    "    training_dic = {\"start\": str(start_training),\n",
    "           \"target\": row['training_volume'],\n",
    "           \"cat\": row['cat_agency_sku'],\n",
    "           \"dynamic_feat\": row['training_sales_promotions'] \n",
    "           }\n",
    "    training_data.append(training_dic)\n",
    "\n",
    "    \n",
    "\n",
    "test_data = []\n",
    "for _,row in df_merge2.iterrows():\n",
    "    test_dic = {\"start\": str(start_training),\n",
    "           \"target\": row['volume'],\n",
    "           \"cat\": row['cat_agency_sku'],\n",
    "           \"dynamic_feat\": row['sales_promotions'] \n",
    "           }\n",
    "    test_data.append(test_dic)\n",
    "\n",
    "\n",
    "# create batch transform input: predicting volume demand for each SKU and agency pair for 201801 - 201812 given dynamic_feat--'sales' and 'promotions' remain the same as of 2017\n",
    "batch_transform_input = []\n",
    "for _,row in df_merge2.iterrows():\n",
    "    batch_dic = {\"start\": str(start_training),\n",
    "           \"target\": row['volume'],\n",
    "           \"cat\": row['cat_agency_sku'],\n",
    "           \"dynamic_feat\": row['batch_sales_promotions'] \n",
    "           }\n",
    "    batch_transform_input.append(batch_dic)\n",
    "\n",
    "    \n",
    "    \n",
    "#dataset for calculating predicted volume for each series in the test set\n",
    "data_for_calculating_predicted = []\n",
    "for _,row in df_merge2.iterrows():\n",
    "    calculating_predicted_dic = {\"start\": str(start_training),\n",
    "           \"target\": row['training_volume'],\n",
    "           \"cat\": row['cat_agency_sku'],\n",
    "           \"dynamic_feat\": row['sales_promotions'] \n",
    "           }\n",
    "    data_for_calculating_predicted.append(calculating_predicted_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Transforming dictionary to json lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# correct np narray\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "# convert to json lines: each line is a json object\n",
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d, cls=NumpyEncoder).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "\n",
    "write_dicts_to_file(\"train.json\", training_data)\n",
    "write_dicts_to_file(\"test.json\", test_data)\n",
    "write_dicts_to_file(\"batch_transform_input.json\", batch_transform_input)\n",
    "write_dicts_to_file(\"data_for_calculating_predicted.json\", data_for_calculating_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Copying the local json lines to S3 where DeepAR can access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_NAME = 'sagemaker-us-east-2-939910653043'\n",
    "upload_file(\"train.json\", BUCKET_NAME, object_name= \"product-demand-forecast-deepar/data/train.json\")\n",
    "upload_file(\"test.json\", BUCKET_NAME, object_name= \"product-demand-forecast-deepar/data/test.json\")\n",
    "upload_file(\"batch_transform_input.json\", BUCKET_NAME, object_name= \"product-demand-forecast-deepar/batch_transform_input.json\")\n",
    "upload_file(\"data_for_calculating_predicted.json\", BUCKET_NAME, object_name= \"product-demand-forecast-deepar/data_for_calculating_predicted.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2013-01-01 00:00:00\", \"target\": [80.676, 98.064, 133.704, 147.312, 175.608, 180.792, 149.796, 161.136, 147.744, 149.364, 95.36399999999999, 104.544, 100.54799999999999, 123.552, 125.17200000000001, 70.524, 21.924, 66.744, 89.1, 107.352, 100.87200000000001, 113.292, 68.148, 75.492, 41.58, 58.32, 87.37200000000001, 81.0, 91.90799999999999, 86.616, 135.0, 97.632, 103.464, 92.016, 54.864, 40.608000000000004, 55.836000000000006, 52.812, 88.992, 66.63600000000001, 49.14, 4.32, 54.4319999999...\n"
     ]
    }
   ],
   "source": [
    "# have a look to what was just written to S3. Now data has been successfully customized to json line which is required by DeepAR\n",
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(BUCKET_NAME + \"/product-demand-forecast-deepar/data/test.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:500] + \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
